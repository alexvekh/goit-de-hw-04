SparkUI learning

У першому коді ми спостерігаємо 5 jobs
- Job 0 складається з одного Stage, яка складається з трьох Tasks:	 
    - Сканування csv файлу спарком
	- Оптимізації SQL в байт код
	- Затросування трансформацій до всіх патрицій
- Job 1 теж складається з одного Stage, яка складається з 4-х Tasks
	- Сканування scv файлу
	- десеріалізує їх у об'єкти DataFrame (у вигляді Row)
	- виконання Spark SQL-запиту у вигляді RDD
	- Затросування трансформацій до всіх патрицій
- Job 2 теж складається з одного Stage, яка складається з трьох Tasks таких самих як і в Job 0 проте вони не такі низкорівневі в java, а виконується наш python-код. 
 	- Сканування csv файлу
	- Оптимізації SQL в байт код
	- Затросування трансформацій до всіх патрицій
    - Бачимо що відбувся Shuffle Write для наступнтої job
- Job 3 ми спостерішаємо вже пропущену стадію, яка була виконана в попередньому job І ми бачимо прочитані дані з диску, які були записані попереднім job. 
 	- Операція обміну даними між partitions на різних виконавчих узлах. 
    - Оптимізація. Замість того, щоб виконувати кожну операцію окремо, Spark генерує єдиний оптимізований Java код. 
    - Процес shuffle переміщення даних між узлами. Після цього Spark переміщає рядки так, щоб всі однакові категорії були в одній partition.
    - І знову бачимо запис даних на диск для наступтох job 
- Job 4 вже дві пропущені стадії і прочитані дані з диску, які були записані попереднім job. 
 	- Адаптивне вирівнювання partitions. 
    - Оптимізація. Генерація адаптивного Java коду. 
    - Внутрішня оптимізація partitions

У другому коді, де добавлено проміжний action collect ми спостерігаємо 8 jobs (Пратично 3 jobs були добавлені для виконання цієї акції)
- Job 0 та Job 1 такі самі як і в попередьому.
- Jobs 2 , 3, 4 такі самі як і в попередьому коді, проте вони відносяться до виконання добавленої проміжної акції collect
- Jobs 5 , 6, 7 такі самі як і попередні, але вони вже стосуються фінальної акції collect.

У третьому коді, де використовується cache ми спостерігаємо 7 jobs
- Job 0 та Job 1 такі самі як і в попередьому.
- Jobs 2 , 3, 4 теж схожі на попередній код, але добавлена одна task у кінці job 4:
    - Внутрішня оптимізація partitions зі списком виконаного коду. Мабуть це процес кешування чи оптимізація одразу після кешування. 
- Jobs 5 пропущені 2 стадії:
    - Exchange - park перерозподіляє (shuffle) дані між partitions.
    - WholeStageCodegen - генерація єдиного блоку Java-коду
    - MapPartitionInternal - обробка даних на рівні partitions
    - MapPartitionInternal (cache) - обробки кешованих даних
    - InMemoryTableScan (cache) - зчитує дані з кешу Spark
    - MapPartitionInternal - повторно після зчитування кешованих даних трансформації над partitions.
- Jobs 6 схожа на попередню, теж пропущені 2 стадії:
    - Exchange - park перерозподіляє (shuffle) дані між partitions.
    - WholeStageCodegen - генерація єдиного блоку Java-коду
    - MapPartitionInternal - обробка даних на рівні partitions
    - MapPartitionInternal (cache) - обробки кешованих даних
    - InMemoryTableScan (cache) - зчитує дані з кешу Spark
    - WholeStageCodegen - генерація єдиного блоку Java-коду, мабуть для вмконання наших розрахунків (.where("count>2"))
    - MapPartitionInternal - повторно після зчитування кешованих даних трансформації над partitions.